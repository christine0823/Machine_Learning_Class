{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of dataset:', (20640, 8))\n",
      "('Shape of label:', (20640,))\n",
      "18576\n",
      "0\n",
      "0.985461\n",
      "1\n",
      "0.970916\n",
      "2\n",
      "0.956565\n",
      "3\n",
      "0.942409\n",
      "4\n",
      "0.928256\n",
      "5\n",
      "0.914275\n",
      "6\n",
      "0.900471\n",
      "7\n",
      "0.886742\n",
      "8\n",
      "0.87326\n",
      "9\n",
      "0.859927\n",
      "10\n",
      "0.846744\n",
      "11\n",
      "0.833953\n",
      "12\n",
      "0.821903\n",
      "13\n",
      "0.8107\n",
      "14\n",
      "0.800359\n",
      "15\n",
      "0.79058\n",
      "16\n",
      "0.781645\n",
      "17\n",
      "0.773505\n",
      "18\n",
      "0.76595\n",
      "19\n",
      "0.759062\n",
      "20\n",
      "0.752789\n",
      "21\n",
      "0.747463\n",
      "22\n",
      "0.743134\n",
      "23\n",
      "0.739824\n",
      "24\n",
      "0.737282\n",
      "25\n",
      "0.735313\n",
      "26\n",
      "0.733769\n",
      "27\n",
      "0.732407\n",
      "28\n",
      "0.73129\n",
      "29\n",
      "0.730433\n",
      "30\n",
      "0.72955\n",
      "31\n",
      "0.728643\n",
      "32\n",
      "0.727588\n",
      "33\n",
      "0.726372\n",
      "34\n",
      "0.724913\n",
      "35\n",
      "0.723277\n",
      "36\n",
      "0.72135\n",
      "37\n",
      "0.719078\n",
      "38\n",
      "0.716507\n",
      "39\n",
      "0.713622\n",
      "40\n",
      "0.710488\n",
      "41\n",
      "0.707139\n",
      "42\n",
      "0.703569\n",
      "43\n",
      "0.699801\n",
      "44\n",
      "0.695862\n",
      "45\n",
      "0.691806\n",
      "46\n",
      "0.687652\n",
      "47\n",
      "0.683378\n",
      "48\n",
      "0.67902\n",
      "49\n",
      "0.674575\n",
      "50\n",
      "0.670034\n",
      "51\n",
      "0.665407\n",
      "52\n",
      "0.660659\n",
      "53\n",
      "0.655783\n",
      "54\n",
      "0.650805\n",
      "55\n",
      "0.645698\n",
      "56\n",
      "0.640478\n",
      "57\n",
      "0.635109\n",
      "58\n",
      "0.629587\n",
      "59\n",
      "0.623954\n",
      "60\n",
      "0.618217\n",
      "61\n",
      "0.612394\n",
      "62\n",
      "0.606474\n",
      "63\n",
      "0.600481\n",
      "64\n",
      "0.594441\n",
      "65\n",
      "0.588358\n",
      "66\n",
      "0.582263\n",
      "67\n",
      "0.576179\n",
      "68\n",
      "0.570128\n",
      "69\n",
      "0.564072\n",
      "70\n",
      "0.558039\n",
      "71\n",
      "0.552053\n",
      "72\n",
      "0.546105\n",
      "73\n",
      "0.540215\n",
      "74\n",
      "0.534388\n",
      "75\n",
      "0.528621\n",
      "76\n",
      "0.522899\n",
      "77\n",
      "0.51722\n",
      "78\n",
      "0.511583\n",
      "79\n",
      "0.505992\n",
      "80\n",
      "0.500424\n",
      "81\n",
      "0.494905\n",
      "82\n",
      "0.489432\n",
      "83\n",
      "0.483993\n",
      "84\n",
      "0.478581\n",
      "85\n",
      "0.473217\n",
      "86\n",
      "0.467891\n",
      "87\n",
      "0.46262\n",
      "88\n",
      "0.457434\n",
      "89\n",
      "0.452321\n",
      "90\n",
      "0.447272\n",
      "91\n",
      "0.442304\n",
      "92\n",
      "0.437396\n",
      "93\n",
      "0.432538\n",
      "94\n",
      "0.427737\n",
      "95\n",
      "0.422979\n",
      "96\n",
      "0.418281\n",
      "97\n",
      "0.413642\n",
      "98\n",
      "0.409039\n",
      "99\n",
      "0.404455\n",
      "100\n",
      "0.399927\n",
      "101\n",
      "0.395477\n",
      "102\n",
      "0.3911\n",
      "103\n",
      "0.38681\n",
      "104\n",
      "0.382602\n",
      "105\n",
      "0.378436\n",
      "106\n",
      "0.374372\n",
      "107\n",
      "0.370366\n",
      "108\n",
      "0.366416\n",
      "109\n",
      "0.362481\n",
      "110\n",
      "0.358562\n",
      "111\n",
      "0.354617\n",
      "112\n",
      "0.350685\n",
      "113\n",
      "0.34678\n",
      "114\n",
      "0.342873\n",
      "115\n",
      "0.339004\n",
      "116\n",
      "0.335227\n",
      "117\n",
      "0.331522\n",
      "118\n",
      "0.32789\n",
      "119\n",
      "0.324343\n",
      "120\n",
      "0.320913\n",
      "121\n",
      "0.317638\n",
      "122\n",
      "0.314514\n",
      "123\n",
      "0.311557\n",
      "124\n",
      "0.308704\n",
      "125\n",
      "0.305869\n",
      "126\n",
      "0.303017\n",
      "127\n",
      "0.300212\n",
      "128\n",
      "0.29748\n",
      "129\n",
      "0.294778\n",
      "130\n",
      "0.292132\n",
      "131\n",
      "0.289514\n",
      "132\n",
      "0.286967\n",
      "133\n",
      "0.284483\n",
      "134\n",
      "0.282042\n",
      "135\n",
      "0.279654\n",
      "136\n",
      "0.277369\n",
      "137\n",
      "0.275191\n",
      "138\n",
      "0.273154\n",
      "139\n",
      "0.271202\n",
      "140\n",
      "0.269329\n",
      "141\n",
      "0.267542\n",
      "142\n",
      "0.265829\n",
      "143\n",
      "0.264204\n",
      "144\n",
      "0.262639\n",
      "145\n",
      "0.26113\n",
      "146\n",
      "0.259641\n",
      "147\n",
      "0.258158\n",
      "148\n",
      "0.256726\n",
      "149\n",
      "0.255345\n",
      "150\n",
      "0.254041\n",
      "151\n",
      "0.252835\n",
      "152\n",
      "0.251699\n",
      "153\n",
      "0.250609\n",
      "154\n",
      "0.249583\n",
      "155\n",
      "0.248618\n",
      "156\n",
      "0.247728\n",
      "157\n",
      "0.246926\n",
      "158\n",
      "0.246172\n",
      "159\n",
      "0.245466\n",
      "160\n",
      "0.244788\n",
      "161\n",
      "0.24414\n",
      "162\n",
      "0.243575\n",
      "163\n",
      "0.243079\n",
      "164\n",
      "0.242633\n",
      "165\n",
      "0.242234\n",
      "166\n",
      "0.241905\n",
      "167\n",
      "0.24167\n",
      "168\n",
      "0.241484\n",
      "169\n",
      "0.241343\n",
      "170\n",
      "0.241238\n",
      "171\n",
      "0.241163\n",
      "172\n",
      "0.241153\n",
      "173\n",
      "0.241211\n",
      "174\n",
      "0.241354\n",
      "175\n",
      "0.241571\n",
      "176\n",
      "0.241849\n",
      "177\n",
      "0.242165\n",
      "178\n",
      "0.242545\n",
      "179\n",
      "0.242923\n",
      "180\n",
      "0.243314\n",
      "181\n",
      "0.243724\n",
      "182\n",
      "0.244133\n",
      "183\n",
      "0.244526\n",
      "184\n",
      "0.24492\n",
      "185\n",
      "0.245336\n",
      "186\n",
      "0.245799\n",
      "187\n",
      "0.246299\n",
      "188\n",
      "0.246857\n",
      "189\n",
      "0.247492\n",
      "190\n",
      "0.248185\n",
      "191\n",
      "0.24894\n",
      "192\n",
      "0.249732\n",
      "193\n",
      "0.250547\n",
      "194\n",
      "0.251397\n",
      "195\n",
      "0.252281\n",
      "196\n",
      "0.253196\n",
      "197\n",
      "0.25415\n",
      "198\n",
      "0.255079\n",
      "199\n",
      "0.255981\n",
      "('Training cost=', 0.28782779, '\\n')\n",
      "('Testing cost=', 0.25598109, '\\n')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "###### Do not modify here ###### \n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = graph_def\n",
    "    #strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "###### Do not modify  here ######\n",
    "\n",
    "def feature_normalize(train_X):\n",
    "\n",
    "    global mean, std\n",
    "    mean = np.mean(train_X, axis=0)\n",
    "    std = np.std(train_X, axis=0)\n",
    "\n",
    "    return (train_X - mean) / std\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "housing = fetch_california_housing()\n",
    "print(\"Shape of dataset:\", housing.data.shape)\n",
    "print(\"Shape of label:\", housing.target.shape)\n",
    "m, n = housing.data.shape\n",
    "\n",
    "train_num = int(m*0.9)\n",
    "print train_num\n",
    "\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "y = y.reshape(-1,1)\n",
    "###### Implement Data Preprocess here ######\n",
    "trainX = X[:train_num]\n",
    "trainY = y[:train_num]\n",
    "trainX = feature_normalize(trainX)\n",
    "\n",
    "testX = X[train_num:]\n",
    "testY = y[train_num:]\n",
    "testX = feature_normalize(testX)\n",
    "\n",
    "inputX = tf.placeholder(tf.float32, [None, n])\n",
    "inputY = tf.placeholder(tf.float32, [None, 1])\n",
    "W = tf.Variable(tf.zeros([n,1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "#y = Wx + b\n",
    "learning_rate = 0.01\n",
    "Y = tf.add(tf.matmul(inputX, W), b)\n",
    "loss = tf.reduce_mean(tf.abs(Y - inputY) / inputY)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss) \n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "training_epochs = 200\n",
    "\n",
    "###### Start TF session ######\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        print epoch\n",
    "        sess.run(optimizer, feed_dict={ inputX: trainX, inputY: trainY})\n",
    "        c = sess.run(loss, feed_dict={inputX: testX, inputY: testY})\n",
    "        print c\n",
    "    \n",
    "    training_cost = sess.run(loss, feed_dict={inputX: trainX, inputY: trainY})\n",
    "    weight = sess.run(W)\n",
    "    bias = sess.run(b)\n",
    "    print(\"Training cost=\", training_cost, '\\n')\n",
    "    \n",
    "    testing_cost = sess.run(loss, feed_dict={inputX: testX, inputY: testY})\n",
    "    weight = sess.run(W)\n",
    "    bias = sess.run(b)\n",
    "    print(\"Testing cost=\", testing_cost, '\\n')\n",
    "    #show_graph(tf.get_default_graph().as_graph_def())\n",
    "###### Start TF session ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
